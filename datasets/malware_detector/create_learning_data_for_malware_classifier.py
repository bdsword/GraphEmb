#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import itertools
import networkx as nx
import pickle
import sqlite3
import argparse
import os
import sys
import random
import progressbar
import time
import re
import traceback
from config import archs
from utils.graph_utils import extract_main_graph
from utils.graph_utils import create_acfg_from_file
from models.embedding_network import EmbeddingNetwork


def n_hot(max_node_num, ids):
    v = np.zeros(max_node_num)
    if ids is not None:
        np.put(v, ids, 1)
    return v


def get_graph_info_mat(graph, max_node_num, attributes_dim, emb_size):
    graph = graph['graph']
    neighbors = []
    attributes = []

    undir_graph = graph.to_undirected()
    undir_graph = nx.relabel.convert_node_labels_to_integers(undir_graph, first_label=0)

    if max_node_num < len(undir_graph):
        raise ValueError('Number of nodes in graph "{}" is larger than MaxNodeNum: {} >= MaxNodeNum'.format(undir_graph, len(undir_graph)))

    attr_names = ['num_calls', 'num_transfer', 'num_arithmetic', 'num_instructions', 'betweenness_centrality', 'num_offspring', 'num_string', 'num_numeric_constant']
    for idx in range(max_node_num):
        node_id = idx
        if node_id in undir_graph.nodes:
            neighbor_ids = list(undir_graph.neighbors(node_id)) 
            neighbors.append(n_hot(max_node_num, neighbor_ids))
            attrs = []
            for attr_name in attr_names:
                attrs.append(undir_graph.nodes[node_id][attr_name])
            attributes.append(attrs)
        else:
            neighbors.append(n_hot(max_node_num, None))
            attributes.append(np.zeros(attributes_dim))
    return neighbors, attributes, np.zeros((max_node_num, emb_size))


# End of copy

def load_graph(graph_path):
    graph = None
    with open(graph_path, 'rb') as f:
        graph = pickle.load(f)
    return graph


def dict_factory(cursor, row):
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d


external_symbol_fillcolor = '#ff00ff'
def get_function_list(graph):
    func_names = []
    for node_name in graph.nodes:
        fillcolor = re.findall(r'"(.*)"', graph.nodes[node_name]['fillcolor'])[0]
        function_name = graph.nodes[node_name]['label']
        if fillcolor != external_symbol_fillcolor:
            function_name = re.findall(r'"(.*)\\+l"', function_name)[0]
            func_names.append(function_name)

    return func_names


def build_func_embs(funcs_dot_dict, arch, sess, args, norm_graph_emb_inference, neighbors_test, attributes_test, u_init_test, create_cache=True, cache_path=None):
    func_embs = {}
    for func in funcs_dot_dict:
        func_dot = funcs_dot_dict[func]
        if not os.path.isfile(func_dot):
            print('{} does not exist.'.format(func_dot))
            embs = np.zeros(args.EmbeddingSize)
        else:
            dot_statinfo = os.stat(func_dot)
            if dot_statinfo.st_size == 0:
                embs = np.zeros(args.EmbeddingSize)
            else:
                path_without_ext = os.path.splitext(func_dot)[0]
                acfg_plk = path_without_ext + '.maxnode{}_emb{}.acfg.plk'.format(args.MaxNodeNum, args.EmbeddingSize)

                # Try to create function ACFG pickled file if pickle file do not exist
                if not os.path.isfile(acfg_plk):
                    try:
                        acfg = create_acfg_from_file(func_dot, arch)
                        if create_cache:
                            with open(acfg_plk, 'wb') as f:
                                pickle.dump(acfg, f)
                    except Exception as e:
                        print('!!! Failed to process {}. !!!'.format(func_dot))
                        print('Exception: {}'.format(e))
                        print()
                        continue
                else:
                    with open(acfg_plk, 'rb') as f:
                        acfg = pickle.load(f)

                if len(acfg) <= args.MaxNodeNum:
                    neighbors, attributes, u_init = get_graph_info_mat({'graph': acfg}, args.MaxNodeNum, args.AttrDims, args.EmbeddingSize)
                    embs = sess.run(norm_graph_emb_inference, {neighbors_test: [neighbors], attributes_test: [attributes], u_init_test: [u_init]})[0]
                else:
                    raise IndexError('{} contain funciton {} which has more node num than {}. ({} > {})'.format(func_dot, func, args.MaxNodeNum, len(acfg), args.MaxNodeNum))
        func_embs[func] = embs

    if create_cache and not cache_path:
        with open(cache_path, 'wb') as f:
            pickle.dump(func_embs, f)
    return func_embs


def embed_func_emb_to_graph(graph, function_embs):
    default_dims = len(function_embs[list(function_embs.keys())[0]])
    for node in graph.nodes:
        func_name = graph.nodes[node]['label'].lstrip('"').rstrip('\\l"')
        if func_name in function_embs:
            graph.nodes[node]['attributes'] = function_embs[func_name]
        else:
            graph.nodes[node]['attributes'] = np.zeros(default_dims)
    return graph


def create_acg(sample_dir, sess, args, norm_graph_emb_inference, neighbors_test, attributes_test, u_init_test, create_cache=True):
    sample_name = os.path.basename(sample_dir)
    cg_path = os.path.join(sample_dir, sample_name + '.dot')
    funcs_dir = os.path.join(sample_dir, sample_name + '_functions')
    acg_plk = os.path.join(sample_dir, sample_name + '.maxnode{}_emb{}.acg.plk'.format(args.MaxNodeNum, args.EmbeddingSize))
    cache_func_embs_plk = os.path.join(sample_dir, sample_name + '.maxnode{}_emb{}.func_embs.plk'.format(args.MaxNodeNum, args.EmbeddingSize))

    main_graph = extract_main_graph(cg_path)
    if len(main_graph) > args.MaxNodeNum:
        print('{} has node number {} > {}. (Ignored)'.format(sample_name, len(main_graph), args.MaxNodeNum))
        return None

    funcs = get_function_list(main_graph)
    func_dots = {}
    for func in funcs:
        func_dots[func] = os.path.join(funcs_dir, func + '.dot')
    try:
        func_embs = build_func_embs(func_dots, 'x86_64_O0', sess, args, norm_graph_emb_inference, neighbors_test, attributes_test, u_init_test, True, cache_func_embs_plk)
        acg = embed_func_emb_to_graph(main_graph, func_embs)
    except IndexError as e:
        print(e)
        return None

    if create_cache:
        with open(acg_plk, 'wb') as f:
            pickle.dump(acg, f)
    return acg


def main(argv):
    parser = argparse.ArgumentParser(description='Create learning data for malware classification according to the given malware and benign samples.')
    parser.add_argument('MODEL_DIR', help='The folder to save the model.')
    parser.add_argument('OutputPlk', help='Path to the output pickle file.')
    parser.add_argument('--MalwareSamplesDir', help='Path to the target folder that contains malwares.', required=True)
    parser.add_argument('--BenignSamplesDir', help='Path to the target folder that contains benign wares.', required=True)
    parser.add_argument('--MalwarePool', help='Path to the pickled positive pool file.')
    parser.add_argument('--BenignwarePool', help='Path to the pickled negative pool file.')
    parser.add_argument('--Seed', type=int, default=0, help='Seed to the random number generator.')
    parser.add_argument('--GPU_ID', type=int, default=0, help='The GPU ID of the GPU card.')
    parser.add_argument('--TF_LOG_LEVEL', default=3, type=int, help='Environment variable to TF_CPP_MIN_LOG_LEVEL')
    parser.add_argument('--T', type=int, default=5, help='The T parameter in the model.(How many hops to propagate information to.)')
    parser.add_argument('--MaxNodeNum', type=int, default=200, help='The max number of nodes per ACFG.')
    parser.add_argument('--AttrDims', type=int, default=8, help='The number of dimensions of attributes.')
    parser.add_argument('--NumberOfRelu', type=int, default=2, help='The number of relu layer in the sigma function.')
    parser.add_argument('--EmbeddingSize', type=int, default=64, help='The dimension of the embedding vectors.')
    parser.add_argument('--MaxNumModelToKeep', type=int, default=100, help='The number of model to keep in the saver directory.')
    args = parser.parse_args()

    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"   # see issue #152
    os.environ["CUDA_VISIBLE_DEVICES"] = str(args.GPU_ID)
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = str(args.TF_LOG_LEVEL)

    if not os.path.isdir(args.MODEL_DIR):
        print('MODEL_DIR folder should be a valid folder.')
        sys.exit(-2)

    neighbors_test = tf.placeholder(tf.float32, shape=(None, args.MaxNodeNum, args.MaxNodeNum), name='neighbors_test')
    attributes_test = tf.placeholder(tf.float32, shape=(None, args.MaxNodeNum, args.AttrDims), name='attributes_test')
    u_init_test = tf.placeholder(tf.float32, shape=(None, args.MaxNodeNum, args.EmbeddingSize), name='u_init_test')

    with tf.variable_scope("siamese") as scope:
        embedding_network = EmbeddingNetwork(args.NumberOfRelu, args.MaxNodeNum, args.EmbeddingSize, args.AttrDims, args.T)
        graph_emb_inference = embedding_network.embed(neighbors_test, attributes_test, u_init_test)
        norm_graph_emb_inference = tf.nn.l2_normalize(graph_emb_inference, 1)

    with tf.Session() as sess:
        saver = tf.train.Saver(max_to_keep=args.MaxNumModelToKeep)
        states = tf.train.get_checkpoint_state(args.MODEL_DIR)
        saver.restore(sess, states.model_checkpoint_path)

        count = 0
        malware_list = []
        for malware in os.listdir(args.MalwareSamplesDir):
            malware_dir = os.path.join(args.MalwareSamplesDir, malware)
            malware_functions_dir = os.path.join(malware_dir, malware + '_functions')
            if not os.path.isdir(malware_functions_dir):
                print('{} do not have _functions directory. Please run ida-pro to extract function flow graph for it.'.format(malware_functions_dir))
                continue
            acg = create_acg(malware_dir, sess, args, norm_graph_emb_inference, neighbors_test, attributes_test, u_init_test, create_cache=True)
            if acg is not None:
                malware_list.append({'graph': acg, 'identifier': malware})
                count += 1
                print('Current Count: ', count)
                if count % 100 == 0:
                    with open('malware_list.plk', 'wb') as f:
                        pickle.dump(malware_list, f)


        count = 0
        benignware_list = []
        for benignware in os.listdir(args.BenignSamplesDir):
            benignware_dir = os.path.join(args.BenignSamplesDir, benignware)
            benignware_functions_dir = os.path.join(benignware_dir, benignware + '_functions')
            if not os.path.isdir(benignware_functions_dir):
                print('{} do not have _functions directory. Please run ida-pro to extract function flow graph for it.'.format(benignware_functions_dir))
                continue
            acg = create_acg(benignware_dir, sess, args, norm_graph_emb_inference, neighbors_test, attributes_test, u_init_test, create_cache=True)
            if acg is not None:
                benignware_list.append({'graph': acg, 'identifier': benignware})
                count += 1
                if count % 100 == 0:
                    with open('benignware_list.plk', 'wb') as f:
                        pickle.dump(benignware_list, f)

        print('malware_list: ', len(malware_list))
        print('benignware_list: ', len(benignware_list))


        learning_data = {'samples': malware_list + benignware_list, 'label': len(malware_list) * [1] + len(benignware_list) * [0]}
        with open(args.OutputPlk, 'wb') as f:
            pickle.dump(learning_data, f)


if __name__ == '__main__':
    main(sys.argv)
